{
    "alibaba\/tongyi-deepresearch-30b-a3b:free": "مدل تحقیقاتی عمیق Tongyi با اندازه 30 میلیارد پارامتر که توسط علی‌بابا توسعه یافته است",
    "allenai\/olmo-3-32b-think:free": "مدل زبان بزرگ OLMO نسخه 3 با اندازه 32 میلیارد پارامتر برای تفکر",
    "allenai\/olmo-3.1-32b-think:free": "مدل زبان بزرگ OLMO با اندازه 32 میلیارد پارامتر که برای تفکر و استدلال طراحی شده است",
    "arcee-ai\/trinity-mini:free": "مدل کوچک Trinity که توسط Arcee AI توسعه یافته است",
    "cognitivecomputations\/dolphin-mistral-24b-venice-edition:free": "نسخه ونیس مدل Dolphin-Mistral با اندازه 24 میلیارد پارامتر",
    "deepseek\/deepseek-r1-0528:free": "مدل DeepSeek نسخه R1 تاریخ 0528 که توسط DeepSeek توسعه یافته است",
    "google\/gemini-2.0-flash-exp:free": "مدل Gemini نسخه 2.0 سریع تجربی که توسط Google توسعه یافته است",
    "google\/gemma-3-12b-it:free": "مدل Gemma نسخه 3 با قابلیت توضیح و اندازه 12 میلیارد پارامتر",
    "google\/gemma-3-27b-it:free": "مدل Gemma نسخه 3 با قابلیت توضیح و اندازه 27 میلیارد پارامتر",
    "google\/gemma-3-4b-it:free": "مدل Gemma نسخه 3 با قابلیت توضیح و اندازه 4 میلیارد پارامتر",
    "google\/gemma-3n-e2b-it:free": "مدل Gemma نسخه 3 با قابلیت توضیح و اندازه 2 میلیارد پارامتر",
    "google\/gemma-3n-e4b-it:free": "مدل Gemma نسخه 3 با قابلیت توضیح و اندازه 4 میلیارد پارامتر",
    "kwaipilot\/kat-coder-pro:free": "مدل برنامه‌نویس KAT-Coder حرفه‌ای که توسط KwaiPilot توسعه یافته است",
    "meta-llama\/llama-3.1-405b-instruct:free": "مدل دستورالعملی Llama نسخه 3.1 با اندازه 405 میلیارد پارامتر",
    "meta-llama\/llama-3.2-3b-instruct:free": "مدل دستورالعملی Llama نسخه 3.2 با اندازه 3 میلیارد پارامتر",
    "meta-llama\/llama-3.3-70b-instruct:free": "مدل دستورالعملی Llama نسخه 3.3 با اندازه 70 میلیارد پارامتر",
    "mistralai\/devstral-2512:free": "مدل زبانی Devstral نسخه 2512 که توسط Mistral AI توسعه یافته است",
    "mistralai\/mistral-7b-instruct:free": "مدل دستورالعملی Mistral با اندازه 7 میلیارد پارامتر",
    "mistralai\/mistral-small-3.1-24b-instruct:free": "مدل دستورالعملی Mistral کوچک نسخه 3.1 با اندازه 24 میلیارد پارامتر",
    "moonshotai\/kimi-k2:free": "مدل Kimi نسخه K2 که توسط Moonshot AI توسعه یافته است",
    "nex-agi\/deepseek-v3.1-nex-n1:free": "نسخه بهبودیافته DeepSeek نسخه 3.1 که توسط Nex-AGI توسعه یافته است",
    "nousresearch\/hermes-3-llama-3.1-405b:free": "مدل Hermes نسخه 3 مبتنی بر Llama 3.1 با اندازه 405 میلیارد پارامتر",
    "nvidia\/nemotron-3-nano-30b-a3b:free": "مدل Nemotron 3 با اندازه 30 میلیارد پارامتر که توسط NVIDIA توسعه یافته است",
    "nvidia\/nemotron-nano-12b-v2-vl:free": "مدل Nemotron Nano نسخه 2 با قابلیت بینایی و اندازه 12 میلیارد پارامتر",
    "nvidia\/nemotron-nano-9b-v2:free": "مدل Nemotron Nano نسخه 2 با اندازه 9 میلیارد پارامتر",
    "openai\/gpt-oss-120b:free": "مدل GPT متن‌باز با اندازه 120 میلیارد پارامتر که توسط OpenAI توسعه یافته است",
    "openai\/gpt-oss-20b:free": "مدل GPT متن‌باز با اندازه 20 میلیارد پارامتر که توسط OpenAI توسعه یافته است",
    "qwen\/qwen-2.5-vl-7b-instruct:free": "مدل دستورالعملی Qwen نسخه 2.5 با قابلیت بینایی و اندازه 7 میلیارد پارامتر",
    "qwen\/qwen3-4b:free": "مدل Qwen نسخه 3 با اندازه 4 میلیارد پارامتر",
    "qwen\/qwen3-coder:free": "مدل برنامه‌نویس Qwen نسخه 3 که توسط Qwen توسعه یافته است",
    "tngtech\/deepseek-r1t-chimera:free": "مدل ترکیبی DeepSeek-R1T که توسط TNG Tech توسعه یافته است",
    "tngtech\/deepseek-r1t2-chimera:free": "مدل ترکیبی DeepSeek-R1T2 که توسط TNG Tech توسعه یافته است",
    "tngtech\/tng-r1t-chimera:free": "مدل ترکیبی TNG-R1T که توسط TNG Tech توسعه یافته است",
    "xiaomi\/mimo-v2-flash:free": "مدل زبانی سریع و سبک MIMO نسخه 2 که توسط شیائومی توسعه یافته است",
    "z-ai\/glm-4.5-air:free": "مدل GLM نسخه 4.5 سبک و سریع که توسط Z-AI توسعه یافته است"
}
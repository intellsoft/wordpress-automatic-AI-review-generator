name: Publish Docs Articles To Wiki (WordPress AI Plugin)

on:
  schedule:
    # Sunday 21:30 UTC = Monday 01:00 Iran
    - cron: "30 21 * * 0"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Clone target Wiki
        run: |
          git clone https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/intellsoft/wordpress-automatic-AI-review-generator.wiki.git wiki

      - name: Fetch source documentation page
        run: |
          curl -L "https://intellsoft.ir/docs/%d8%b1%d8%a7%d9%87%d9%86%d9%85%d8%a7%db%8c-%d8%a7%d9%81%d8%b2%d9%88%d9%86%d9%87-%d9%88%d8%b1%d8%af%d9%be%d8%b1%d8%b3-%d8%aa%d9%88%d9%84%db%8c%d8%af-%d8%ae%d9%88%d8%af%da%a9%d8%a7%d8%b1-%d9%86%d8%b8/" -o source.html

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install beautifulsoup4 requests

      - name: Extract documentation sections using Python
        run: |
          mkdir -p articles
          python3 - <<PYTHON
          import os
          from bs4 import BeautifulSoup

          with open("source.html", encoding="utf-8") as f:
              soup = BeautifulSoup(f, "html.parser")

          # Ø±ÙˆØ´ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ø®ØªØ§Ø± ØµÙØ­Ù‡ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§ÙØ²ÙˆÙ†Ù‡
          # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ (h1, h2) Ùˆ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
          articles_data = []
          
          # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù…Ø³ØªÙ†Ø¯Ø§Øª (Ù…Ø¹Ù…ÙˆÙ„Ø§ Ø¯Ø± <article> ÛŒØ§ <main>)
          main_content = soup.find("article") or soup.find("main") or soup.find("div", class_="content")
          if not main_content:
              main_content = soup.body
          
          current_title = None
          current_content = []
          
          for element in main_content.find_all(["h1", "h2", "h3", "hr"]):
              if element.name == "hr":
                  if current_title and current_content:
                      articles_data.append((current_title, "\n".join(current_content)))
                  current_title = None
                  current_content = []
                  continue
                  
              if element.name in ["h1", "h2", "h3"]:
                  if current_title and current_content:
                      articles_data.append((current_title, "\n".join(current_content)))
                  
                  current_title = element.get_text(strip=True)
                  current_content = []
                  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø¯Ø± ØªØ§ Ù‡Ø¯Ø± Ø¨Ø¹Ø¯ÛŒ
                  for sibling in element.find_next_siblings():
                      if sibling.name in ["h1", "h2", "h3", "hr"]:
                          break
                      text = sibling.get_text(strip=True)
                      if text and sibling.name not in ["script", "style"]:
                          current_content.append(text)
          
          # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ø¨Ø®Ø´
          if current_title and current_content:
              articles_data.append((current_title, "\n".join(current_content)))

          # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ÙˆÛŒÚ˜Ù‡ Ø§Ø² README Ú¯ÙˆÙ†Ù‡ (ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ØŒ Ù†ØµØ¨ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§)
          special_sections = {
              "ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯": "âœ¨",
              "ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ": "ðŸŽ¯",
              "Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÛŒØ¹": "ðŸš€",
              "Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡": "ðŸ› ",
              "Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ": "ðŸ“ž"
          }
          
          for title, emoji in special_sections.items():
              header = soup.find(["h1", "h2", "h3"], string=lambda text: text and title in text)
              if header:
                  content = []
                  for sibling in header.find_next_siblings():
                      if sibling.name in ["h1", "h2", "h3"]:
                          break
                      text = sibling.get_text(strip=True)
                      if text and sibling.name not in ["script", "style"]:
                          content.append(text)
                  if content:
                      articles_data.append((f"{emoji} {title}", "\n".join(content)))

          # Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„ Ù„ÛŒØ³Øª
          with open("articles/list.txt", "w", encoding="utf-8") as out:
              for title, content in articles_data:
                  # Ø³Ø§Ø®Øª Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø§Ø² Ø¹Ù†ÙˆØ§Ù†
                  slug = "".join(c for c in title if c.isalnum() or c.isspace()).replace(" ", "-")
                  slug = slug[:50].strip("-")  # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø·ÙˆÙ„
                  out.write(f"{slug}\t{title}\t{content[:200]}...\n")
          PYTHON

      - name: Generate detailed Wiki pages
        run: |
          while IFS=$'\t' read -r slug title preview; do
            file="wiki/$slug.md"
            
            if [ -f "$file" ]; then
              echo "Wiki page already exists: $title"
              continue
            fi
            
            echo "Creating Wiki page: $title"
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø² ÙØ§ÛŒÙ„ Ù…Ù†Ø¨Ø¹ (Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø² Ø®ÙˆØ¯ ØµÙØ­Ù‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…)
            # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø³Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ØŒ Ø¯Ø± Ø¹Ù…Ù„ Ø¨Ø§ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø² source.html Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´ÙˆØ¯
            
            # Ø§ÛŒØ¬Ø§Ø¯ ØµÙØ­Ù‡ ÙˆÛŒÚ©ÛŒ Ø¨Ø§ ÙØ±Ù…Øª Ù…Ù†Ø§Ø³Ø¨
            {
              echo "# $title"
              echo ""
              echo "Ø§ÛŒÙ† ØµÙØ­Ù‡ Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø³Ù…ÛŒ Ø§ÙØ²ÙˆÙ†Ù‡ **ØªÙˆÙ„ÛŒØ¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ù†Ø¸Ø±Ø§Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙˆØ±Ø¯Ù¾Ø±Ø³** Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª."
              echo ""
              echo "---"
              echo ""
              echo "$preview"
              echo ""
              echo "---"
              echo "ðŸ“š **Ù…Ù†Ø¨Ø¹ Ø§ØµÙ„ÛŒ:**"
              echo ""
              echo "ðŸ‘‰ [Ù…Ø´Ø§Ù‡Ø¯Ù‡ ØµÙØ­Ù‡ Ú©Ø§Ù…Ù„ Ù…Ø³ØªÙ†Ø¯Ø§Øª](https://intellsoft.ir/docs/%d8%b1%d8%a7%d9%d8%b1%d8%af%d9%be%d8%b1%d8%b3-%d8%aa%d9%88%d9%84%db%8c%d8%af-%d8%ae%d9%88%d8%af%da%a9%d8%a7%d8%b1-%d9%86%d8%b8/?utm_source=github_wiki&utm_medium=wiki&utm_campaign=wordpress_ai_review)"
              echo ""
              echo "> **Ù†Ú©ØªÙ‡:** Ø§ÛŒÙ† ØµÙØ­Ù‡ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙˆØ³Ø· GitHub Actions Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø³Ù…ÛŒ Ø§ÙØ²ÙˆÙ†Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯."
            } > "$file"
            
          done < articles/list.txt

      - name: Commit and push to Wiki
        run: |
          cd wiki
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add .
          git commit -m "Auto sync WordPress AI Review Generator documentation to Wiki" || exit 0
          git push
